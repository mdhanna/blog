{
  
    
        "post0": {
            "title": "Pull dog photos",
            "content": "subscription_key = &quot;54ae23fb26514eaf8236f5bd89a96f07&quot; search_url = &quot;https://api.bing.microsoft.com/v7.0/images/search&quot; headers = {&quot;Ocp-Apim-Subscription-Key&quot; : subscription_key} . path = Path(&#39;/storage/dogs&#39;) . . names = [&#39;english&#39;, &#39;american&#39;] if not path.exists(): path.mkdir() for o in names: print(o) dest = (path/o) dest.mkdir(exist_ok=True) params = {&quot;q&quot;: &#39;{} labrador retriever&#39;.format(o), &quot;license&quot;: &quot;public&quot;, &quot;imageType&quot;: &quot;photo&quot;, &quot;count&quot;:&quot;150&quot;} response = requests.get(search_url, headers=headers, params=params) response.raise_for_status() search_results = response.json() img_urls = [img[&#39;contentUrl&#39;] for img in search_results[&quot;value&quot;]] download_images(dest, urls=img_urls) . english . american . fns = get_image_files(path) fns . (#300) [Path(&#39;/storage/dogs/english/00000044.jpg&#39;),Path(&#39;/storage/dogs/english/00000093.png&#39;),Path(&#39;/storage/dogs/english/00000098.jpg&#39;),Path(&#39;/storage/dogs/english/00000100.jpg&#39;),Path(&#39;/storage/dogs/english/00000122.jpg&#39;),Path(&#39;/storage/dogs/english/00000062.jpg&#39;),Path(&#39;/storage/dogs/english/00000074.jpg&#39;),Path(&#39;/storage/dogs/english/00000101.jpg&#39;),Path(&#39;/storage/dogs/english/00000056.jpg&#39;),Path(&#39;/storage/dogs/english/00000029.jpg&#39;)...] . from collections import Counter fns_subdirs = [p.parts[1] for p in fns] counts = Counter(fns_subdirs) counts . Counter({&#39;storage&#39;: 300}) . insufficient_data_paths = [k for k, v in counts.items() if v &lt; 150] insufficient_data_paths . [] . len([x for x in names if x not in insufficient_data_paths]) . 2 . for name in insufficient_data_paths: shutil.rmtree(path/name) . fns_updated = get_image_files(path) failed = verify_images(fns_updated) failed . (#1) [Path(&#39;/storage/dogs/english/00000133.svg&#39;)] . from collections import Counter failed_subdirs = [p.parts[1] for p in failed] Counter(failed_subdirs) . Counter({&#39;storage&#39;: 1}) . failed.map(Path.unlink); . No data cleaning . def process_dog_data(): dogs = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=44), get_y=parent_label, item_tfms=Resize(128) ) dogs = dogs.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), # batch_tfms=aug_transforms() ) return dogs.dataloaders(path) . dls = process_dog_data() . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.392489 | 0.944025 | 0.389831 | 00:15 | . epoch train_loss valid_loss error_rate time . 0 | 1.134894 | 0.818585 | 0.305085 | 00:15 | . 1 | 1.009688 | 0.807327 | 0.322034 | 00:15 | . 2 | 0.898921 | 0.833640 | 0.338983 | 00:15 | . 3 | 0.781876 | 0.854603 | 0.372881 | 00:15 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(5,5)) . interp.plot_top_losses(5, nrows=1) . cleaner = ImageClassifierCleaner(learn) cleaner . After data cleaning . dls = process_dog_data() learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.255060 | 0.726968 | 0.380000 | 00:14 | . epoch train_loss valid_loss error_rate time . 0 | 0.826457 | 0.670593 | 0.380000 | 00:14 | . 1 | 0.797378 | 0.744757 | 0.320000 | 00:15 | . 2 | 0.723976 | 0.809631 | 0.260000 | 00:15 | . 3 | 0.660038 | 0.849696 | 0.280000 | 00:13 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(5,5)) . Turning Your Model into an Online Application . Using the Model for Inference . learn.export() . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . learn_inf = load_learner(path/&#39;export.pkl&#39;) . Creating a Notebook App from the Model . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred .",
            "url": "https://mdhanna.github.io/mels_blog/2020/11/24/bee_classifier.html",
            "relUrl": "/2020/11/24/bee_classifier.html",
            "date": " • Nov 24, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Being Radically Candid amidst the Chaos of 2020",
            "content": "It’d be an understatement to say that so far, 2020 has been a tough year for nearly everyone. From a global pandemic sickening millions of people to civil unrest rocking the United States and beyond, the world seems to have turned upside down. . If you’ve found yourself in a management position during this chaos, **you may be wondering how best to navigate the shift of your company to remote work, the mental health of your team, and the need to address systemic racism in your organization. ** . Applying the concepts behind “Radical Candor” can help you tackle these issues head-on. And anyone—from CEO’s to individual team members—can start using these lessons today to begin effecting change. . What is Radical Candor? . Radical Candor is a 2017 book and management philosophy from Kim Scott, a former manager at Apple and Google. We can sum it up with the following: . **Managers should care personally and challenge directly. ** . Fleshing this out a bit more, Scott created a matrix to show how managers might fall short on either of these goals. . Credit to https://www.radicalcandor.com/our-approach/ . Obnoxious Aggression: A manager who isn’t afraid to challenge his/her employees but has made no effort to show that he/she cares about them as people or is invested in their success. . | Ruinous Empathy: A manager who shies away from providing “uncomfortable” criticism out of fear he/she may hurt their employee’s feelings. The vast majority of managers fall into this category, and this is definitely where I naturally land. . | Manipulative Insincerity: A manager who doesn’t bother to give any direct feedback or show interest in his/her employees’ careers. In other words, the worst kind of manager you could get. . | Radical Candor: A manager who recognizes that giving direct feedback in a respectful manner is the best way to help his/her employees succeed and who takes the time to demonstrate personal and professional investment in them. . | . To sum up,** promoting a trusting environment where team members aren’t afraid to challenge each other or their manager is the quickest way to organizational success. ** I can’t imagine how much time and productivity we lose by withholding from someone the feedback they desperately need if they want to improve their performance at work (or anywhere!). . Compound Interest of Continuous Feedback . Scott also emphasizes the importance of real-time feedback. You might typically bottle up all your feedback for Employee Eric throughout the week and then unleash it on him during your regularly scheduled one-on-one. This can backfire for two reasons. . **Sense of Whiplash: **The situation for which you’re giving Eric this feedback—maybe he presented a sloppy demo to marketing on Monday and couldn’t answer any follow-up questions from the team—is now far in the past. Eric might have thought he knocked that presentation out of the park, and he internalized that view for several days before you dashed cold water all over it. . | **Repeat Offender: **Even worse, Eric might have already given another presentation in the meantime with the same poor quality and lackluster results. . | . While these two possibilities should be reason enough to instate give feedback immediately whenever possible, I like to think about real-time feedback as analogous to compound interest. Any armchair investor knows that continuously compounded interest grows at a much faster rate than annual or “simple” interest. . Credit to https://www.fool.com/knowledge-center/compound-interest.aspx . Feedback works the same way. If we frequently give small amounts of both positive and negative feedback, the recipient will compound their growth accordingly. . Radical Candor Today . Ok, this all sounds like a great way to run a company in normal times. But these are not normal times. What lessons can we learn for today? . Caring Personally . In typical circumstances, showing that you care personally about your employees or team members might not be that simple. Some people don’t like to discuss their personal lives at work or make small talk, especially introverts. And building trust organically takes time. . **But today, checking in on the personal lives of your co-workers and especially your direct reports isn’t just sanctioned—it’s expected. ** . When we first moved to WFH, we needed to understand how this sudden shift was affecting those around us in the new virtual workplace. . Are they feeling isolated/burnt-out/unmotivated? . | _Do they have kids home from school which affect what hours they can be online? _ . | Are they caring for elderly relatives or neighbors that might add to whatever stress they’re already feeling? . | . These conversations started to crack open the door to discuss feelings and invite vulnerability as the line between personal and professional started to blur. . The riots incited by the death of George Floyd and his death itself also warranted checking in with our colleagues. . How are they coping with the sense of unrest roiling our country? . | _How are they feeling in general given current events? _ . | _Has their neighborhood been looted or burned? _ . | Are they safe? . | . These last questions, especially, are not ones I ever expected to ask in my role as a manager. And while I hope these circumstances will never be repeated, I am grateful that this situation has destigmatized discussing our personal emotions at work and has given me the opportunity to show that I care personally about my team as human beings. . Confronting Racism . Our current crisis also necessitates that we act along the other axis above—challenging directly. . I admit that I fell into the contingent of white people who put our heads in the sand by believing that by simply being “not racist”, we had overcome ingrained biases and systemic prejudice in this country. . The death of George Floyd and the protests sweeping the country were a long overdue wake-up call, and like many of my peers, I took the time to try and educate myself. I’ve been reading “How to Be an Anti-Racist” by Ibram X. Kendi, which has been eye-opening. I’m ashamed that I wasn’t aware of much of the historical context around concepts of race and hadn’t realized how claiming to be “colorblind” actually hurt communities of color by turning a blind eye to racist policies. . Kendi’s proposed antidote is that we become actively anti-racist. We must constantly evaluate our beliefs, actions, and words for unconscious bias. Yes, that sounds exhausting, and it is. But people of color have been exhausted for centuries—from slavery, from blatant discrimination, from the possibility of being shot by the police—so much so that it has taken a toll on their physical and mental health. . And we must adopt this anti-racist attitude in the workplace, as well, by challenging directly. Kim Scott herself provided an example of unconscious racism embedded in the first edition of her book in a recent blog post. The book suggested using a stuffed monkey called “Whoops the Monkey” as a prop in the office to encourage team members to discuss their mistakes. As a white woman, Scott did not realize that being called a monkey is a common denigration targeted at black people, and bringing this symbol into the office, especially as a representation of mistakes, was inappropriate. . Likely she would never have known had not someone spoken up. **Only by directly challenging those we see engaging in acts of racism, even unconsciously, can we start to affect real change in mindsets, language, and policies. ** . Conclusion . Radical Candor offers an actionable framework for managers (or anyone!) to create an open environment where direct feedback is delivered promptly and where empathy establishes a relationship of trust. These aspirations also have immediate applications to the world of 2020—by engaging with our co-workers’ personal needs amidst continuing stress and by directly confronting racial attitudes and policies in the workplace. .",
            "url": "https://mdhanna.github.io/mels_blog/management/2020/06/29/being-radically-candid-amidst-the-chaos-of-2020.html",
            "relUrl": "/management/2020/06/29/being-radically-candid-amidst-the-chaos-of-2020.html",
            "date": " • Jun 29, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Applying DAG's to Causal Models",
            "content": "I’ve been reading “The Book of Why” by Judea Pearl over the past few weeks, which has really helped formalize my intuition of causation. However, the book would be much better if Pearl left out any sentences written in the first-person as he has an annoying tendency to style himself as a messiah proclaiming the enlightened concepts of Causation to all the lowly statisticians still stuck on Correlation. . If we can look past his self-aggrandizing remarks, “The Book of Why” applies causal models to examples from the surgeon general’s committee on smoking in the 1960’s to the Monty Hall paradox. By reducing these multi-faceted problems down to a causal representation, we can finally put our finger on contributing factors or “causes” and control for them (if possible) to isolate the effect we are attempting to discover. . Perhaps the biggest takeaway for me from this book is the need to understand the data generation process when working with a dataset. This might sound like a no-brainer but too often, data scientists are so eager to jump in to the big shiny ball pit of a new dataset that they don’t stop to think about what this data actually represents. . Bazinga GIF from Bazinga GIFs _ . Data scientists with a new dataset . _ . By including the process by which the data was generated in these causal models, we can augment our own mental model and unlock the true relationships behind the variables of interest. . So what’s a DAG? . Directly acyclic graphs (DAG’s) are a visual representation of a causal model. Here’s a simple one: . . You were late for work because you had to change your car’s tire because it was flat. Of course, we could add on much more than this (why was it flat?) but you get the idea. . Junction Types . Let’s explore what we can do with DAG’s through different junction types. . Chain . This is the simplest DAG and is represented in the example above. A generalized representation below shows that A is a cause of B, which is itself a cause of C. . . Collider . Now we have two causes for C. Both A and B affect the outcome C. . . Conditioning on C will reveal a non-causal, _negative _correlation between A &amp; B. This correlation is called collider bias. . We can understand this effect in crude mathematical terms. If A + B = C and we hold C constant, then we must increase A by the same amount we decrease B. . Additionally, this phenomenon is sometimes also called the “explain-away effect” because C “explains away” the correlation between A and B. . Note that the collider bias may be positive in cases when contributions from both A and B are necessary to affect C. . An example of a collider relationship would be the age-old nature vs. nurture question. Someone’s personality (C) is a product of both their upbringing (A) and the genes (B). . Fork . In the case of a fork, **A affects both B and C. ** . . Without conditioning on A, there exists a spurious (non-causal) correlation between B &amp; C. A classic example of a spurious correlation is the relationship between crime (B) and ice cream sales (C). When you plot these two values over time, they appear to increase and decrease together, suggesting some kind of causality. Does ice cream cause people to commit crime? . Of course, this relationship can be explained by adding in temperature (A). Warmer weather causes people to leave their homes more often, leading to more crime (B). People also crave ice cream cones (C) on hot days. . Node Types . Mediators . A mediator is the node that “mediates” or transmits a causal effect from one node to another. . Again using the example below, B mediates the causal effect of A onto C. . . Confounders . Harking back to the crime-and-ice-cream example, temperature is the confounder node as it “confounds” the relationship between ice cream sales and crime. . . **If we control for the confounder (A), we can isolate the relationship between C and B, if one exists. ** This is a key concept for experimental design. . Correcting for Confounding . Let’s spend some more time on this subject. Pearl’s assertion is that if we control for all confounders, we should be able to isolate the relationship between the variables of interest and therefore prove causation, instead of mere correlation. . Pearl defines confounding more broadly as any relationship that leads to [latexpage]$P(Y | do(X)) neq P(Y | X)$, where the $do$ operator implies an action. In other words, if there is a difference between the probability of an outcome $Y$ given $X$ and the probability of $Y$ given $X$ in a perfect world in which we were able to change $X$ and only $X$, then confounding is afoot. | . Four Rules of Information Flow . Pearl has 4 rules for controlling the flow of information through a DAG. . 1. In a chain (A -&gt; B -&gt; C), B carries information from A to C. Therefore, controlling for B prevents information about A from reaching C and vice versa. 2. In a fork (A &lt;- B -&gt; C), B is the only known common source of information between both A and C. Therefore, controlling for B prevents information about A from reaching C and vice versa. 3. In a collider (A -&gt; B &lt;- C), controlling for B &quot;opens up&quot; the pipe between A and C due to the explain-away effect. 4. Controlling for descendants of a variable will partially control for the variable itself. Therefore, controlling the descendant of a mediator partially closes the pipe, and controlling for the descendant of a collider partially opens the pipe. . Back-door criterion . We can use these causal models as represented by DAG’s to determine how exactly we should remove this confounding from our study. . If we are interested in understanding the relationship between only X and Y, we must identify and dispatch any confounding back-door paths, where a back-door path is any path from X to Y that starts with an arrow into X. . Pearl’s Games . Pearl devises a series of games that involve increasingly complicated DAG’s where the objective is to “deconfound” the path from X to Y. This is achieved by blocking every non-causal path while leaving all causal paths intact. . In other words, we need to identify and block all back-door paths while ensuring that any variable Z on a back-door path is not a descendant of X via a causal path to Y. . Let’s go through some examples, using the numbered games from the book. . Game 2 . . We need to determine which variables (if any) of A, B, C, D, or E need to be controlled in order to deconfound the path from X to Y. . There is one back-door path: X ← A → B ← D → E → Y. This path is blocked by the collider at B from the third rule of information flow. . Therefore, there is no need to control any of these variables! . Game 5 . . This one’s a bit more interesting. We have two back-door paths: . 1. X ← A → B ← C → Y 2. X ← B ← C → Y . The first back-door path is blocked by a collider at B so there is no need to control any variables due to this relationship. . The second path, however, represents a non-causal path between X and Y. We need to control for either B or C. . But watch out! If we control for B, we fall into the condition outlined by Pearl’s third rule above, where we’ve controlled for a collider and thus opened up the first back-door path in this diagram. . Therefore, if we control for B, we will then have to control for A or C as well. However, we can also control for only C initially and avoid the collider bias altogether. . Conclusion . DAG’s can be an informative way to organize our mental models around causal relationships. Keeping in mind Pearl’s Four Rules of Information Flow, we can identify confounding variables that cloud the true relationship between the variables under study. . Bringing this home for data scientists, when we include the data generation process as a variable in a DAG, we remove much of the mystery surrounding such pitfalls as Simpson’s Paradox. We’re able to think more like informed humans and less like data-crunching machines—an ability we should all be striving for in our increasingly AI-driven world. .",
            "url": "https://mdhanna.github.io/mels_blog/things%20i'm%20reading/2020/06/24/applying-dags-to-causal-models.html",
            "relUrl": "/things%20i'm%20reading/2020/06/24/applying-dags-to-causal-models.html",
            "date": " • Jun 24, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "What is an ROC curve?",
            "content": "Precision and recall aren’t the only ways to quantify our performance when developing a classifier. . Plotting a Receiver Operating Characteristic (ROC) curve is another useful tool to help us** quickly determine how well the classifier performs** and visualize any trade-offs we might be making as we attempt to balance Type I and Type II error rates. . The basics . Let’s jump right in. Here’s an ROC curve for a model that predicts credit card default (where a _positive _is considered to be a default). . . Axes . The x-axis represents the False Positive Rate (FPR) or the probability of a false alarm. This can be calculated through: . [latexpage] $FPR = frac{false positives}{false positives + true negatives}$ . Put another way, FPR represents the fraction of incorrectly classified negatives (in this case, accounts that did not default but for which our model predicted would default) within the total population of negatives (all accounts that did not default). . The y-axis shows the True Positive Rate (TPR), which is equivalent to the recall. . Recall is just class-specific accuracy or: . $recall = frac{true positives}{true positives + false negatives} $ . Again, in the context of our example, this is the fraction of accounts that did default and for which our model predicted they would within the total population of accounts that did default. . The diagonal . The red dashed line dividing the plot represents random performance. When the FPR matches the TPR, we might as well be guessing–you’re right as often as you’re wrong. . If your curve falls to the left of the diagonal, the model is performing better than random because your true positive rate exceeds your false positive rate. Likewise, a curve to the right of the diagonal indicates some systemic error in your model, causing it to perform worse than random. . The curve . Now that we’ve established the space in which we’re working, we can best understand how to determine the ROC curve above. . The ROC visualizes the trade-offs between the FPR and the TPR** when we adjust the threshold by which the classifier makes its determination.** . For example, our model could determine a credit default using a probability threshold of 0.25. If the model’s probability of default is 0.32, we would return “default”. If the probability is 0.19, we could return “no default”. . . This is illustrated in the ROC plot above. The FPR and TPR for a threshold of 0.25 is represented by the black dot on the ROC curve. Our TPR is roughly 0.7 and our FPR is around 0.45. . Now, let’s lower the threshold to 0.15. . . We move further up the curve, increasing our TPR to nearly 0.9 but also increasing our FPR to about 0.75. . This illustrates the principle that as we decrease our decision threshold, we move to the right and upwards along the curve because we are simply classifying more observations overall as positives. Therefore, TPR increases as we capture more of those true positives but at the same time, our probability of false alarm also goes up as we become less strict with our requirement to classify a positive. . Choosing a threshold . This observation begs the question–what would be the optimal threshold to choose? . Of course, this will likely depend on model-specific considerations. For example, what is the cost of a false positive? If it’s relatively low, we might as well increase our TPR at the expense of an increased FPR as well. . However, if we’d like to try and balance these two competing metrics, we can choose the point along the curve that is closest to the top-left corner of the plot. This could be considered the apex of the curve, as shown below. . . The apex can be found by determining where on the curve we find a maximum difference between TPR and FPR. In our case, this occurs at a threshold of 0.29 to return a TPR of nearly 0.6 and a FPR of about 0.36. . AUC . Perhaps the most widely used application of an ROC curve is to calculate the area underneath it. This is called AUC or “Area Under Curve”. . The area in gray below represents the AUC. . . Our AUC for this model is 0.65. A random model would produce an AUC of 0.5 so we are doing better than guessing! . An ideal model would have an ROC curve that hugs the axes with an apex close to the upper-left corner, resulting in an AUC of nearly 1.0. Therefore, AUC is a way to quantify the ability of the model to maximize TPR while minimizing FPR, no matter the threshold chosen. . ## .",
            "url": "https://mdhanna.github.io/mels_blog/data%20science%20basics/2020/06/10/what-is-an-roc-curve.html",
            "relUrl": "/data%20science%20basics/2020/06/10/what-is-an-roc-curve.html",
            "date": " • Jun 10, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Precision vs. recall",
            "content": "Congrats! You’ve built a binary classifier that you’re convinced is totally awesome. . But how do you quantify just how awesome this model is? And more specifically, how do you communicate this model’s level of awesomeness to your manager/product owner/stakeholder/random-person-on-the-street? . This is where performance metrics such as precision and recall come into play, and we’ll attempt to explain the intuition around these in addition to their definitions. . What is the positive class? . If you’ve built a binary classifier, perhaps the first step in determining your performance metric is to select a “positive” class. This is easy in some instances (ex. coronavirus test result) and less so in others (ex. determining if your pet is either a cat or a chinchilla). But establishing these definitions early (and stating them explicitly) will save a lot of confusion down the road. . False negatives vs. true positives . Something I struggled with initially was what exactly did we mean by a “false negative”? Was it a true negative that we classified incorrectly? Or did the model return an incorrect (and therefore false) prediction of negative? In other words, from whose perspective do we consider this classification false? . The answer is the latter definition above. The table below sums this up. . . Confusion matrix . Once you’ve established your false positives and false negatives, you can display them in a confusion matrix that looks very similar to the table above. . Here is an example for a classifier that attempts to determine if shoplifting is taking place (where we define a shoplifting incident as a positive). Let’s say for example, this model takes video footage from a store surveillance system and looks for certain features (ex. a customer picking up an item and hiding it under his/her shirt) that would indicate shoplifting. . The confusion matrix shows the number of observations for each class and the corresponding predictions from the model. . From the matrix above, we can see that our classifier is rather paranoid and often mistakes normal behavior for shoplifting. . Accuracy . Now we can start to sum up the classifier’s performance using a single value, such as the accuracy, which represents the fraction of correct predictions out of the total. In the shoplifting example, the accuracy is shown by the following: . . $accuracy = frac{ text{ true positives} + text{ true negatives}}{ text{ total classified}} = frac{40+ 107}{40+ 107+ 345 + 8} = 0.294$ . Unfortunately, this model is performing far worse than random. . WARNING: Note that accuracy is a misleading metric in this case due to unbalanced class sizes. In other words, because we have so few true shoplifting incidences compared to cases of normal behavior, we can easily achieve an accuracy of 0.904 by returning a prediction of “normal” every time. But no one would consider such a classifier to be truly “accurate”. . Precision and Recall . I mentioned earlier that our classifier tends to overpredict shoplifting–how can we incorporate this tendency into a performance metric? . This is where precision and recall come into play. These metrics are class-specific, which means that we must specify a value for both precision and recall for each class returned by the model. . Precision . Precision is the answer to the question: out of the total predictions for a certain class returned by the model, how many were actually correct? For example, the precision for the shoplifting class is: . . $precision = frac{TP}{TP + FP}$ . . $precision_{shoplifting} = frac{ text{ true shoplifting}}{ text{ total predicted shoplifting}} = frac{40}{40+345} = 0.104$ . . Similarly, for the normal behavior: . . $precision_{normal} = frac{ text{ true normal}}{ text{ total predicted normal}} = frac{107}{107+8} = 0.930$ . . In other words, the model’s predictions for normal behavior were correct 93% of the time, while its predictions for shoplifting were correct only 10% of the time. Yikes. . Recall . I like to think of recall as a class-specific accuracy. How many of the model’s predictions for a certain class were actually correct? . $recall = frac{TP}{TP + FN}$ . . $recall_{shoplifting} = frac{ text{ true shoplifting}}{ text{ total actual shoplifting}} = frac{40}{40+8} = 0.833$ . . $recall_{normal} = frac{ text{ true normal}}{ text{ total actual normal}} = frac{107}{107+345} = 0.237$ . . The model correctly identified 83% of the actual shoplifting incidents. . And here we see the trade-off often inherent in precision and recall. The model correctly predicted a good majority (83%) of the actual shoplifting incidents, but at the expense of also erroneously predicting many truly normal behaviors as shoplifting too (nearly 90% of the predicted shoplifting incidents). . This ties into Type I and Type II errors, where a type I error is a false positive (normal behavior incorrectly classified as shoplifting) and a type II error is a false negative (shoplifting incorrectly classified as normal behavior). . For our situation, this boils down to asking if you would rather have the police called on an innocent customer (type I) or lose merchandise to unchecked shoplifters (type II)? Understanding the costs of type I and type II errors helps to weigh whether you’d like to improve either recall or precision. Often, it’s difficult to do both simultaneously. . F1-Score . However, if you’d like to tie up both precision and recall into one single metric to hand over to your manager/product owner/stakeholder, then the F1-score (sometimes called F-measure) is for you! . This is simply the harmonic mean of the precision and recall for a given class, shown below. . . $F1 = 2 * frac{precision * recall}{precision + recall}$ . . An F1-score of 1 indicates perfect precision and recall. . If you’d like to place more importance on recall over precision, you can introduce a $ beta$ term (set $ beta$ to a value less than 1 to place more emphasis of precision instead of recall). . . $F_{ beta} = (1 + beta^2) * frac{precision * recall}{( beta^2 * precision) + recall}$ . .",
            "url": "https://mdhanna.github.io/mels_blog/data%20science%20basics/2020/05/31/precision-vs-recall.html",
            "relUrl": "/data%20science%20basics/2020/05/31/precision-vs-recall.html",
            "date": " • May 31, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://mdhanna.github.io/mels_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://mdhanna.github.io/mels_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://mdhanna.github.io/mels_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mdhanna.github.io/mels_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}